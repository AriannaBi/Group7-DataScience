{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60e242cc21f08104",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 02807 Final project: Recommendation system\n",
    "Recommendation system of products from __Digital Music__ category on __Amazon__. Products are suggested based on a short description inserted by a user.\n",
    "[**Data source**](https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586320e6b1f6d0c3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ad38c7912c0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import gzip\n",
    "import spacy\n",
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter, defaultdict\n",
    "from lxml import html, etree\n",
    "from nrclex import NRCLex\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979d91cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset if it is not downloaded yet\n",
    "if not os.path.exists('Dataset/meta_Digital_Music.json.gz'):\n",
    "    !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/metaFiles2/meta_Digital_Music.json.gz -P ./Dataset\n",
    "else:\n",
    "    print('Dataset already downloaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9fe8c13463e2f2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "__Data format__\n",
    "   * `asin`: ID of the product, e.g. 0000031852\n",
    "   * `title`: name of the product\n",
    "   * `feature`: bullet-point format features of the product\n",
    "   * `description`: description of the product\n",
    "   * `price`: price in US dollars (at time of crawl)\n",
    "   * `imageURL`: url of the product image\n",
    "   * `imageURL`: url of the high resolution product image\n",
    "   * `related`: related products (also bought, also viewed, bought together, buy after viewing)\n",
    "   * `salesRank`: sales rank information\n",
    "   * `brand`: brand name\n",
    "   * `categories`: list of categories the product belongs to\n",
    "   * `tech1`: the first technical detail table of the product\n",
    "   * `tech2`: the second technical detail table of the product\n",
    "   * `similar`: similar product table\n",
    "\n",
    "_Note that there are usually multiple attributes left out blank for each product (specific attributes differs from product to product)._ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71227ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is in the format: \n",
    "# \"overall\": 4.0,\n",
    "# \"verified\",\n",
    "# \"reviewTime\",\n",
    "# \"reviewerID\",\n",
    "# \"asin\",\n",
    "# \"style\": {\"Format:\"}\n",
    "# \"reviewerName\",\n",
    "# \"reviewText\"\n",
    "# \"summary\",\n",
    "# \"unixReviewTime\"\n",
    "\n",
    "### Load the meta data\n",
    "data = []\n",
    "with gzip.open('Dataset/meta_Digital_Music.json.gz') as f:\n",
    "    for l in f:\n",
    "        data.append(json.loads(l.strip()))\n",
    "    \n",
    "# Total length of list, this number equals total number of products\n",
    "print(\"Total number of items in the dataset: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4144d3174f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list into pandas dataframe\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Change list to strings\n",
    "df.description = df.description.apply(lambda x: \". \".join(x))\n",
    "\n",
    "# A lot of the descriptions (and other features) contain HTML.\n",
    "# The function parses and \"translates\" into plain text descriptions more suitable for analysis\n",
    "def strip_html(s):\n",
    "    if not s or s.isspace(): \n",
    "        return ''\n",
    "    try:\n",
    "        return str(html.fromstring(s).text_content())\n",
    "    except etree.ParserError: # I am not able to find out why the error occur so i continued by catching the exception. Seem to happen on some empty description strings \n",
    "        return ''\n",
    "\n",
    "df.description = df.description.apply(lambda x: strip_html(x))\n",
    "\n",
    "# Filter out descriptions shorter than 100 chars\n",
    "df = df[df['description'].map(lambda d: len(d) >= 100)]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f516632291f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of products after filtering out: \", len(df))\n",
    "print(\"First three product description\")\n",
    "for i in range(3):\n",
    "    print()\n",
    "    print(df.iloc[i].title)\n",
    "    print(df.iloc[i].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3f49bdd0d819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty columns\n",
    "df.replace(\"\", np.nan, inplace=True)\n",
    "df.dropna(how='all', axis=1, inplace=True)\n",
    "\n",
    "# Display final cleaned up pandas dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86d78de3eb7ded3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Adding emotions characteristics of the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68677d2ebfcdbe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying NRCLex emotions\n",
    "df['emotion_nrc'] = df.description.apply(lambda x: NRCLex(x).raw_emotion_scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681db33f280f26a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppressing warning about old version of spacy\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # Applying Spacy affect model emotions\n",
    "    nlp_affect = spacy.load('Spacy-Affect-Model/affect_ner')\n",
    "    \n",
    "df['emotion_spacy'] = df.description.apply(lambda x: Counter([item.label_.lower() for item in nlp_affect(x).ents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e92828edcd356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer method for emotion recognition\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "model.to(device)\n",
    "\n",
    "def get_emotion(text):\n",
    "  input_ids = tokenizer.encode(text + '</s>', return_tensors='pt').to(device)\n",
    "  output = model.generate(input_ids=input_ids,\n",
    "               max_length=2)\n",
    "  dec = [tokenizer.decode(ids) for ids in output]\n",
    "  label = dec[0]\n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38ca22a5644b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the transformer method on our dataset\n",
    "df['emotion_transformer'] = df.description[:1000].apply(lambda x: get_emotion(x)[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b28fe3da46d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting most significant emotion of a particular description\n",
    "def get_most_significant_emotion(emotions):\n",
    "    try:\n",
    "        sign_emotion = max(emotions, key=emotions.get)\n",
    "    except ValueError:\n",
    "        sign_emotion = None\n",
    "    return sign_emotion\n",
    "\n",
    "df['most_significant_emotion_nrc'] = df.emotion_nrc.apply(lambda x: get_most_significant_emotion(x))\n",
    "df['most_significant_emotion_spacy'] = df.emotion_spacy.apply(lambda x: get_most_significant_emotion(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd7f5158ad89132",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Similar items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f40f954faeaa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdescription = df.description\n",
    "descr = defaultdict(list)\n",
    " \n",
    "for idx, row in df.iterrows():\n",
    "    if row.description in descr[row.asin]:\n",
    "        print(idx, row.asin, row.description)\n",
    "    else:\n",
    "        descr[row.asin].append(row.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0a08bcfdacdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89feb2e137dc825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in descr.items():\n",
    "    print(type(value))\n",
    "    # if len(elem.values())  >1:\n",
    "    #     print(elem)d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe40f28c89c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740138949207c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shingle(aString, q, delimiter=' '):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - aString (str): string to split into shingles\n",
    "        - q (int)\n",
    "        - delimiter (str): string of the delimiter to consider to split the input string (default: space)\n",
    "    Return: list of unique shingles\n",
    "    \"\"\"\n",
    "    all_shingles = []\n",
    "    if delimiter != '':\n",
    "        words_list = aString.split(delimiter)\n",
    "    else:\n",
    "        words_list = aString\n",
    "    for i in range (len(words_list)-q+1):\n",
    "        all_shingles.append(delimiter.join(words_list[i:i+q]))\n",
    "    return list(set(all_shingles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918ff303174343",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_string, q = dfdescription.iloc[0], 2\n",
    "# ex_string, q = \"Latin rhythms that will get your kids singing in Spanish. \", 2\n",
    "ex_shingles = shingle(ex_string, q)\n",
    "# assert len(ex_shingles) == 7\n",
    "print('\\nInitial string:', ex_string)\n",
    "print(f'>> Shingles with q = {q} :',ex_shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ed1c7db3871bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfdescription))\n",
    "dfdescription.drop_duplicates(inplace=True)\n",
    "print(len(dfdescription))\n",
    "# dfdescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac1261f9afbbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ccb007f061d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge description to reviews data using 'asin'\n",
    "\n",
    "merged_df = df.merge(df[['asin', 'description']], on='asin', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41847305b093267",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.iloc[15:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f45f49f3d77a62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
